{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoesHage/ML_PROJECT/blob/main/Food_Recognition_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9v9xxeFS_eH"
      },
      "source": [
        "# **Food Item Recognition**\n",
        "\n",
        "We will be using the following 3 models to test which one of them is ideal to our current scenario.\n",
        "*   **SVM**\n",
        "*   **Random Forest**\n",
        "*   **CNN**\n",
        "\n",
        "We need to classify images into 1 of 9 classes using these models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz_VoKowWoUb",
        "outputId": "69add0c1-b1db-460e-ba4f-7c7e14e80ecb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61RnKetUjBLR",
        "outputId": "1e2e776d-7445-438e-88f2-fe1a8951a5cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0               1\n",
            "3               2\n",
            "2               3\n",
            "4               4\n",
            "6               5\n",
            "5               6\n",
            "7               7\n",
            "8               8\n",
            "9               9\n",
            "1    category.txt\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Get the path to the data folder\n",
        "data_folder = \"/content/drive/MyDrive/Food Item Recognition From Images1/data\"\n",
        "\n",
        "# Get a list of all folders in the data folder\n",
        "folders = pd.Series(os.listdir(data_folder)).sort_values()\n",
        "\n",
        "# Print the list of folders\n",
        "print(folders)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBxgMTM2SMgC"
      },
      "source": [
        "# **I. Support Vector Machines**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4P9EdKdVXtP",
        "outputId": "751f774b-fff0-4659-b742-a8cf1539c66f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "SWjQgkD3XOXL",
        "outputId": "df4fbcb8-a436-45dd-9f8b-5653be80196f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: '/content/drive/MyDrive/Food Item Recognition From Images1/data/category.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c85e3c45d40d>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mclass_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/MyDrive/Food Item Recognition From Images1/data/category.txt'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/data\"\n",
        "classes = os.listdir(data_dir)\n",
        "num_classes = len(classes)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i, class_name in enumerate(classes):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_path = os.path.join(class_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None and img.size != 0:  # Check if the image loaded successfully and is not empty\n",
        "            img = cv2.resize(img, (100, 100))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            X.append(img.flatten())\n",
        "            y.append(i)\n",
        "        else:\n",
        "            print(f\"Warning: Unable to load or empty image: {img_path}\")\n",
        "\n",
        "if not X:  # Check if X is empty, indicating all images failed to load\n",
        "    print(\"Error: No images loaded successfully. Please check the data directory.\")\n",
        "    exit()\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_model = SVC(kernel='linear', decision_function_shape='ovr')  # OvA strategy with linear kernel\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn90RHz-Qgkf",
        "outputId": "d876b0d9-98b4-4249-8aaf-ae1165ebdb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/train/1\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/train/2\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/train/3\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/train/4\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/train/5\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/train/6\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/train/7\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/train/8\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/train/9\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/val/1\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/val/2\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/val/3\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/val/4\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/val/5\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/val/6\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/val/7\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/val/8\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/val/9\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/test/1\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/test/2\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/test/3\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/test/4\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/test/5\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/test/6\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/test/7\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/test/8\n",
            "Warning: Unable to load or empty image: /content/drive/MyDrive/data/test/9\n",
            "Accuracy: 0.40252182347235693\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/data\"\n",
        "classes = os.listdir(data_dir)\n",
        "num_classes = len(classes)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i, class_name in enumerate(classes):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_path = os.path.join(class_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is not None and img.size != 0:\n",
        "            img = cv2.resize(img, (100, 100))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            X.append(img.flatten())\n",
        "            y.append(i)\n",
        "        else:\n",
        "            print(f\"Warning: Unable to load or empty image: {img_path}\")\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_model = SVC(kernel='linear', decision_function_shape='ovr')  # OvA strategy with linear kernel\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBqybyf2Sjox"
      },
      "source": [
        "# **II. Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljAv4dNoSrkG",
        "outputId": "c1dee3f8-ba09-40f6-931d-8d1ac787f516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5910418695228822\n",
            "CV Accuracy Scores: [0.50827653 0.60564752 0.54527751 0.59746589 0.50487329]\n",
            "Average CV Accuracy: 0.552308147844457\n",
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "Best parameters found:  {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Best cross-validated accuracy: 0.59\n",
            "Test set accuracy: 0.60\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def extract_features(image_path, image_size=(100, 100)):\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"Error: Unable to load image '{image_path}'\")\n",
        "            return None\n",
        "        image = cv2.resize(image, image_size)\n",
        "        # Convert image to grayscale and flatten the array\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        return gray_image.flatten()\n",
        "    except Exception as e:\n",
        "        print(f\"Error: An exception occurred while processing image '{image_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "with open(os.path.join(data_folder, 'category.txt'), 'r') as category_file:\n",
        "    next(category_file)  # Skip the header line\n",
        "    for line in category_file:\n",
        "        category_id, category_name = line.strip().split('\\t')\n",
        "        category_id = int(category_id)\n",
        "        category_folder = os.path.join(data_folder, str(category_id))\n",
        "        # Iterate over images in the category folder\n",
        "        for image_file in os.listdir(category_folder):\n",
        "            image_path = os.path.join(category_folder, image_file)\n",
        "            # Extract features and append to X\n",
        "            features = extract_features(image_path)\n",
        "            X.append(features)\n",
        "            # Append corresponding label to y\n",
        "            y.append(category_id)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "#Split data into training and testing data, 0.8 and 0.2 respectively.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
        "\n",
        "#Train Random forest classifier on training data\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=32)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "#Evaluation\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "#Using 10 fold cross validation\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=32)\n",
        "cv_scores = cross_val_score(rf_classifier, X, y, cv=5)\n",
        "print(f\"CV Accuracy Scores: {cv_scores}\")\n",
        "print(f\"Average CV Accuracy: {np.mean(cv_scores)}\")\n",
        "\n",
        "#Using hyperParameter tuning to find the ideal estimator.\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=32)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validated accuracy: {:.2f}\".format(grid_search.best_score_))\n",
        "\n",
        "#Testing the best model we got from the grid search's estimator\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test set accuracy: {:.2f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAUi7bhirzFj"
      },
      "source": [
        "Using only the testing, training data we check the accuracy of the model and it gives a moderate 0.58.\n",
        "Now we move on and add 10 fold cross validation for a more accurate accuracy score: 0.54.\n",
        "We now want to improve the model more by using hyperparameter tuning and getting the best parameters for a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN39_0t0Sr-5"
      },
      "source": [
        "# **III. Convolutional neural networks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIw28UODS7su",
        "outputId": "48669289-bf41-4d1b-a883-df19c075702c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEVS_WJaBNge"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDU3Z9cF7lsH",
        "outputId": "a651527c-69e6-44f3-e833-e7eac719ff27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category 1 has 1650 images.\n",
            "Category 2 has 71 images.\n",
            "Category 3 has 675 images.\n",
            "Category 4 has 514 images.\n",
            "Category 5 has 27 images.\n",
            "Category 6 has 107 images.\n",
            "Category 7 has 675 images.\n",
            "Category 8 has 772 images.\n",
            "Category 9 has 660 images.\n"
          ]
        }
      ],
      "source": [
        "# Data Preparation and Preprocessing\n",
        "data_dir = \"/content/drive/MyDrive/data\"\n",
        "\n",
        "\n",
        "# Check the number of images in each category\n",
        "for i in range(1, 10):\n",
        "    path = os.path.join(data_dir, str(i))\n",
        "    print(f'Category {i} has {len(os.listdir(path))} images.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ibbHc3iZTz4"
      },
      "outputs": [],
      "source": [
        "# Function to identify and remove corrupted images\n",
        "def verify_images(folder_path):\n",
        "    for fname in os.listdir(folder_path):\n",
        "        fpath = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            img = tf.io.read_file(fpath)\n",
        "            img = tf.io.decode_image(img)\n",
        "        except:\n",
        "            print(f'Removing corrupted image: {fpath}')\n",
        "            os.remove(fpath)\n",
        "\n",
        "# Apply the cleaning function to each category\n",
        "for i in range(1, 10):\n",
        "    verify_images(os.path.join(data_dir, str(i)))\n",
        "\n",
        "# Create directories for train, validation, and test sets\n",
        "sets = ['train', 'val', 'test']\n",
        "for s in sets:\n",
        "    set_path = os.path.join(data_dir, s)\n",
        "    if not os.path.exists(set_path):\n",
        "        os.makedirs(set_path)\n",
        "    for i in range(1, 10):\n",
        "        class_path = os.path.join(set_path, str(i))\n",
        "        if not os.path.exists(class_path):\n",
        "            os.makedirs(class_path)\n",
        "\n",
        "# Split the data into train, validation, and test folders\n",
        "def split_data(source, dest_train, dest_val, dest_test, split_train=0.8, split_val=0.1):\n",
        "    files = os.listdir(source)\n",
        "    np.random.shuffle(files)\n",
        "    train_idx = int(len(files) * split_train)\n",
        "    val_idx = int(len(files) * (split_train + split_val))\n",
        "    for file in files[:train_idx]:\n",
        "        shutil.copy(os.path.join(source, file), os.path.join(dest_train, file))\n",
        "    for file in files[train_idx:val_idx]:\n",
        "        shutil.copy(os.path.join(source, file), os.path.join(dest_val, file))\n",
        "    for file in files[val_idx:]:\n",
        "        shutil.copy(os.path.join(source, file), os.path.join(dest_test, file))\n",
        "\n",
        "# Apply the splitting function\n",
        "for i in range(1, 10):\n",
        "    src_folder = os.path.join(data_dir, str(i))\n",
        "    train_folder = os.path.join(data_dir, 'train', str(i))\n",
        "    val_folder = os.path.join(data_dir, 'val', str(i))\n",
        "    test_folder = os.path.join(data_dir, 'test', str(i))\n",
        "    split_data(src_folder, train_folder, val_folder, test_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkGun2qFaK-x",
        "outputId": "765e3ef4-afee-4b78-fa11-7601e1d30085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4950 images belonging to 9 classes.\n",
            "Found 984 images belonging to 9 classes.\n",
            "Epoch 1/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 2s/step - accuracy: 0.3403 - loss: 1.8998 - val_accuracy: 0.5729 - val_loss: 1.2209\n",
            "Epoch 2/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3750 - loss: 1.6413 - val_accuracy: 0.7083 - val_loss: 0.9884\n",
            "Epoch 3/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 2s/step - accuracy: 0.5951 - loss: 1.1131 - val_accuracy: 0.7385 - val_loss: 0.7650\n",
            "Epoch 4/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.8720 - val_accuracy: 0.7500 - val_loss: 0.7374\n",
            "Epoch 5/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 2s/step - accuracy: 0.7263 - loss: 0.7609 - val_accuracy: 0.8125 - val_loss: 0.5350\n",
            "Epoch 6/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 1.0499 - val_accuracy: 0.7083 - val_loss: 1.0054\n",
            "Epoch 7/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 2s/step - accuracy: 0.8075 - loss: 0.5701 - val_accuracy: 0.8771 - val_loss: 0.4062\n",
            "Epoch 8/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.3394 - val_accuracy: 0.9167 - val_loss: 0.3233\n",
            "Epoch 9/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 2s/step - accuracy: 0.8652 - loss: 0.3785 - val_accuracy: 0.9104 - val_loss: 0.3104\n",
            "Epoch 10/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.1988 - val_accuracy: 0.9583 - val_loss: 0.2365\n",
            "Epoch 11/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 2s/step - accuracy: 0.9005 - loss: 0.2973 - val_accuracy: 0.9292 - val_loss: 0.2593\n",
            "Epoch 12/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.9688 - loss: 0.2383 - val_accuracy: 0.9167 - val_loss: 0.1687\n",
            "Epoch 13/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 2s/step - accuracy: 0.9351 - loss: 0.1911 - val_accuracy: 0.9417 - val_loss: 0.2342\n",
            "Epoch 14/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.3233 - val_accuracy: 1.0000 - val_loss: 0.0848\n",
            "Epoch 15/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 2s/step - accuracy: 0.9520 - loss: 0.1519 - val_accuracy: 0.9542 - val_loss: 0.1806\n",
            "Epoch 16/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.1855 - val_accuracy: 0.9167 - val_loss: 0.2812\n",
            "Epoch 17/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 2s/step - accuracy: 0.9672 - loss: 0.1066 - val_accuracy: 0.9646 - val_loss: 0.1830\n",
            "Epoch 18/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0524 - val_accuracy: 0.9583 - val_loss: 0.0922\n",
            "Epoch 19/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 2s/step - accuracy: 0.9657 - loss: 0.0965 - val_accuracy: 0.9615 - val_loss: 0.1765\n",
            "Epoch 20/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.1077 - val_accuracy: 0.9583 - val_loss: 0.3459\n",
            "Epoch 21/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 2s/step - accuracy: 0.9784 - loss: 0.0745 - val_accuracy: 0.9552 - val_loss: 0.2026\n",
            "Epoch 22/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0747 - val_accuracy: 0.9583 - val_loss: 0.1810\n",
            "Epoch 23/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 2s/step - accuracy: 0.9833 - loss: 0.0593 - val_accuracy: 0.9615 - val_loss: 0.1971\n",
            "Epoch 24/50\n",
            "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1742 - val_accuracy: 0.9583 - val_loss: 0.1099\n"
          ]
        }
      ],
      "source": [
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(9, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Set up image data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'train'),\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'val'),\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Adjusted Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "steps_per_epoch = len(train_generator.filenames) // train_generator.batch_size\n",
        "validation_steps = len(val_generator.filenames) // val_generator.batch_size\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,  # dynamically adjusted\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=validation_steps,  # dynamically adjusted\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPZRsNVNxgTu",
        "outputId": "455cb588-ef6a-47a9-da8c-164d6f9785ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 972 images belonging to 9 classes.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 736ms/step - accuracy: 0.9529 - loss: 0.1787\n",
            "Test accuracy: 0.9578189253807068\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'test'),\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}