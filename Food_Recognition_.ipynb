{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoesHage/ML_PROJECT/blob/main/Food_Recognition_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9v9xxeFS_eH"
      },
      "source": [
        "# **Food Item Recognition**\n",
        "\n",
        "We will be using the following 3 models to test which one of them is ideal to our current scenario.\n",
        "*   **SVM**\n",
        "*   **Random Forest**\n",
        "*   **CNN**\n",
        "\n",
        "We need to classify images into 1 of 9 classes using these models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz_VoKowWoUb",
        "outputId": "225f10d4-7bd1-4c3d-b15e-f4d5f4c01c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61RnKetUjBLR",
        "outputId": "dc391cb0-0db9-401a-f947-f186d8ace92f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2               1\n",
            "4               2\n",
            "1               3\n",
            "5               4\n",
            "7               5\n",
            "6               6\n",
            "8               7\n",
            "9               8\n",
            "0               9\n",
            "3    category.txt\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Get the path to the data folder\n",
        "data_folder = \"/content/drive/MyDrive/Food Item Recognition From Images1 (1)/data\"\n",
        "\n",
        "# Get a list of all folders in the data folder\n",
        "folders = pd.Series(os.listdir(data_folder)).sort_values()\n",
        "\n",
        "# Print the list of folders\n",
        "print(folders)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBxgMTM2SMgC"
      },
      "source": [
        "# **I. Support Vector Machines**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn90RHz-Qgkf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBqybyf2Sjox"
      },
      "source": [
        "# **II. Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljAv4dNoSrkG",
        "outputId": "c1dee3f8-ba09-40f6-931d-8d1ac787f516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5910418695228822\n",
            "CV Accuracy Scores: [0.50827653 0.60564752 0.54527751 0.59746589 0.50487329]\n",
            "Average CV Accuracy: 0.552308147844457\n",
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "Best parameters found:  {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Best cross-validated accuracy: 0.59\n",
            "Test set accuracy: 0.60\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def extract_features(image_path, image_size=(100, 100)):\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"Error: Unable to load image '{image_path}'\")\n",
        "            return None\n",
        "        image = cv2.resize(image, image_size)\n",
        "        # Convert image to grayscale and flatten the array\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        return gray_image.flatten()\n",
        "    except Exception as e:\n",
        "        print(f\"Error: An exception occurred while processing image '{image_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "with open(os.path.join(data_folder, 'category.txt'), 'r') as category_file:\n",
        "    next(category_file)  # Skip the header line\n",
        "    for line in category_file:\n",
        "        category_id, category_name = line.strip().split('\\t')\n",
        "        category_id = int(category_id)\n",
        "        category_folder = os.path.join(data_folder, str(category_id))\n",
        "        # Iterate over images in the category folder\n",
        "        for image_file in os.listdir(category_folder):\n",
        "            image_path = os.path.join(category_folder, image_file)\n",
        "            # Extract features and append to X\n",
        "            features = extract_features(image_path)\n",
        "            X.append(features)\n",
        "            # Append corresponding label to y\n",
        "            y.append(category_id)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "#Split data into training and testing data, 0.8 and 0.2 respectively.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
        "\n",
        "#Train Random forest classifier on training data\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=32)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "#Evaluation\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "#Using 10 fold cross validation\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=32)\n",
        "cv_scores = cross_val_score(rf_classifier, X, y, cv=5)\n",
        "print(f\"CV Accuracy Scores: {cv_scores}\")\n",
        "print(f\"Average CV Accuracy: {np.mean(cv_scores)}\")\n",
        "\n",
        "#Using hyperParameter tuning to find the ideal estimator.\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=32)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validated accuracy: {:.2f}\".format(grid_search.best_score_))\n",
        "\n",
        "#Testing the best model we got from the grid search's estimator\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test set accuracy: {:.2f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAUi7bhirzFj"
      },
      "source": [
        "Using only the testing, training data we check the accuracy of the model and it gives a moderate 0.58.\n",
        "Now we move on and add 10 fold cross validation for a more accurate accuracy score: 0.54.\n",
        "We now want to improve the model more by using hyperparameter tuning and getting the best parameters for a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN39_0t0Sr-5"
      },
      "source": [
        "# **III. Convolutional neural networks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIw28UODS7su",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac8d1f5-52b9-4c20-f0bd-4f946b10cec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Directory containing the images\n",
        "data_dir = \"/content/drive/MyDrive/data\"\n",
        "categories = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
        "\n",
        "# Directory for train, validation, and test sets\n",
        "output_dir = \"output\"\n",
        "train_dir = os.path.join(output_dir, \"train\")\n",
        "val_dir = os.path.join(output_dir, \"validation\")\n",
        "test_dir = os.path.join(output_dir, \"test\")\n",
        "\n",
        "# Create output directories if they don't exist\n",
        "for directory in [train_dir, val_dir, test_dir]:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# Helper function to check if an image is corrupted\n",
        "def is_image_valid(file_path):\n",
        "    try:\n",
        "        img = Image.open(file_path)\n",
        "        img.verify()  # Verify that it is, in fact, an image\n",
        "        return True\n",
        "    except (IOError, SyntaxError) as e:\n",
        "        return False\n",
        "\n",
        "# Split data and move to appropriate folders\n",
        "for category in categories:\n",
        "    category_path = os.path.join(data_dir, category)\n",
        "    all_files = [os.path.join(category_path, f) for f in os.listdir(category_path) if is_image_valid(os.path.join(category_path, f))]\n",
        "\n",
        "    train_files, test_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
        "    val_files, test_files = train_test_split(test_files, test_size=0.5, random_state=42)\n",
        "\n",
        "    for file_set, dest_dir in [(train_files, train_dir), (val_files, val_dir), (test_files, test_dir)]:\n",
        "        dest_category_dir = os.path.join(dest_dir, category)\n",
        "        if not os.path.exists(dest_category_dir):\n",
        "            os.makedirs(dest_category_dir)\n",
        "\n",
        "        for file_path in file_set:\n",
        "            shutil.copy(file_path, dest_category_dir)\n",
        "\n",
        "print(\"Data successfully split into training, validation, and test sets.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSgP07t-P1B0",
        "outputId": "9e5051e3-6801-4c7c-96cd-41d46651ee5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully split into training, validation, and test sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Directory paths\n",
        "batch_size = 32\n",
        "img_height = 150\n",
        "img_width = 150\n",
        "\n",
        "train_gen = ImageDataGenerator(rescale=1./255, rotation_range=30, horizontal_flip=True)\n",
        "val_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_data = train_gen.flow_from_directory(train_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
        "val_data = val_gen.flow_from_directory(val_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
        "test_data = test_gen.flow_from_directory(test_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
        "\n",
        "# Build CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(categories), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbP2yQPNQdVh",
        "outputId": "a857d02f-7e11-42f6-ab81-254264344b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4118 images belonging to 9 classes.\n",
            "Found 514 images belonging to 9 classes.\n",
            "Found 519 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks for preventing overfitting\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(train_data, validation_data=val_data, epochs=50, callbacks=[early_stop, checkpoint])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOK5Cy2DQmCN",
        "outputId": "ed0032a0-f2d0-4920-a03a-008f7b48eddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "129/129 [==============================] - ETA: 0s - loss: 13.4678 - accuracy: 0.4140"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r129/129 [==============================] - 270s 2s/step - loss: 13.4678 - accuracy: 0.4140 - val_loss: 9.9703 - val_accuracy: 0.1634\n",
            "Epoch 2/50\n",
            "129/129 [==============================] - 272s 2s/step - loss: 5.9478 - accuracy: 0.5036 - val_loss: 2.6637 - val_accuracy: 0.2393\n",
            "Epoch 3/50\n",
            "129/129 [==============================] - 268s 2s/step - loss: 2.3305 - accuracy: 0.5481 - val_loss: 4.7167 - val_accuracy: 0.4047\n",
            "Epoch 4/50\n",
            "129/129 [==============================] - 271s 2s/step - loss: 1.3183 - accuracy: 0.5937 - val_loss: 1.7309 - val_accuracy: 0.5156\n",
            "Epoch 5/50\n",
            "129/129 [==============================] - 265s 2s/step - loss: 1.0474 - accuracy: 0.6428 - val_loss: 1.3184 - val_accuracy: 0.6089\n",
            "Epoch 6/50\n",
            "129/129 [==============================] - 267s 2s/step - loss: 0.9691 - accuracy: 0.6819 - val_loss: 1.2381 - val_accuracy: 0.6634\n",
            "Epoch 7/50\n",
            "129/129 [==============================] - 264s 2s/step - loss: 0.9437 - accuracy: 0.6938 - val_loss: 1.0548 - val_accuracy: 0.6965\n",
            "Epoch 8/50\n",
            "129/129 [==============================] - 269s 2s/step - loss: 0.8819 - accuracy: 0.7040 - val_loss: 0.8744 - val_accuracy: 0.7004\n",
            "Epoch 9/50\n",
            "129/129 [==============================] - 264s 2s/step - loss: 0.8488 - accuracy: 0.7130 - val_loss: 1.2668 - val_accuracy: 0.6809\n",
            "Epoch 10/50\n",
            "129/129 [==============================] - 264s 2s/step - loss: 0.7488 - accuracy: 0.7322 - val_loss: 0.9288 - val_accuracy: 0.6848\n",
            "Epoch 11/50\n",
            "129/129 [==============================] - 257s 2s/step - loss: 0.7707 - accuracy: 0.7382 - val_loss: 1.0090 - val_accuracy: 0.7101\n",
            "Epoch 12/50\n",
            " 24/129 [====>.........................] - ETA: 3:20 - loss: 0.8700 - accuracy: 0.7203"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}